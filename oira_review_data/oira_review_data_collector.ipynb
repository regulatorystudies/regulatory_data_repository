{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhoudanxie/regulatory_data_repository/blob/main/oira_review_data/oira_review_data_collector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **OIRA Review Data Collector**\n",
        "\n",
        "This notebook contains Python code to download and organize data on rulemaking actions reviewed by the [Office of Information and Regulatory Affairs](https://www.reginfo.gov/public/do/XMLReportList) since 1981.\n",
        "\n",
        "It will generate a clean CSV file covering all the actions reviewed by OIRA during the time period that an user specifies. The CSV file contains information on each action including RIN, rule title, agency code, agency name, date and year received, date and year completed, rule stage, economic significance, major rule status, legal deadline, and decision.\n",
        "\n",
        "How to use this notebook:\n",
        "\n",
        "Step 1: To start, click \"Open in Colab\" above to open a Colab notebook.\n",
        "\n",
        "Step 2: On the notebook page, click Runtime in the top menu, and then click \"Run all\". If a warning message pops out, select \"Run anyway\".\n",
        "\n",
        "Step 3: Follow the instructions shown to enter the timeframe of the data you are requesting."
      ],
      "metadata": {
        "id": "yxbDjU-ws_-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "#%% Library\n",
        "from xml.etree import ElementTree\n",
        "import csv\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import ipywidgets as widgets\n",
        "import warnings\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import xml.etree.cElementTree as et\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_columns', 10)\n",
        "from lxml import etree\n",
        "import requests\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# !pip install pandas_read_xml | grep -v 'already satisfied'\n",
        "!pip install -q pandas_read_xml\n",
        "import pandas_read_xml as pdx\n",
        "from pandas_read_xml import flatten, fully_flatten, auto_separate_tables"
      ],
      "metadata": {
        "id": "6xO5mU57EYmo",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Fetch current year\n",
        "current_time = datetime.now()\n",
        "current_year = current_time.year"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ldrnqUlOPChx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Download agency name & code crosswalk\n",
        "#download xml file\n",
        "url_agy = 'https://raw.githubusercontent.com/zhoudanxie/regulatory_data_repository/main/other_data/AGY_AGENCY_LIST.xml'\n",
        "path_agy = f'/content/AGY_AGENCY_LIST.xml'\n",
        "r = requests.get(url_agy, allow_redirects=True)\n",
        "open(path_agy, 'wb').write(r.content)\n",
        "\n",
        "#open xml file\n",
        "with open(path_agy, 'r') as f:\n",
        "     test_xml = f.read()\n",
        "\n",
        "#extract information from xml\n",
        "df = pdx.read_xml(test_xml, ['OIRA_DATA'])\n",
        "df = df.pipe(flatten)\n",
        "df = df.pipe(flatten)\n",
        "\n",
        "agy_info = pd.DataFrame({'agency_code': df['AGENCY|AGENCY_CODE'].astype(int), 'agency_name': df['AGENCY|NAME']})"
      ],
      "metadata": {
        "id": "hpbAk9QYaiQW",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Function to convert XML to dataframe\n",
        "def oira_tranformation(filepath):\n",
        "\n",
        "    # Adding header to CSV File:\n",
        "    agency_code, rin, title, stage, ES, date_received,\\\n",
        "    legal_deadline, date_completed, decision, date_published,\\\n",
        "    health_care_act, Dodd_Frank_Act, international_impacts,\\\n",
        "    unfunded_mandates, major, homeland_security, regulatory_flexibility_analysis = ([] for i in range(17))\n",
        "\n",
        "\n",
        "    # Parse XML File\n",
        "    #xml = ElementTree.parse(filepath)\n",
        "    parser = etree.XMLParser(encoding=\"UTF-8\", recover=True)\n",
        "    parsed_xml = etree.parse(filepath, parser)  # prevent form issue\n",
        "    xml = parsed_xml.getroot()\n",
        "\n",
        "\n",
        "    # For each regulatory act:\n",
        "    for regact in xml.findall(\"REGACT\"):\n",
        "            if (regact):\n",
        "                # Extract Reg act details:\n",
        "                agency_code.append(int(regact.find(\"AGENCY_CODE\").text))\n",
        "                rin.append(regact.find(\"RIN\").text)\n",
        "                title.append(regact.find(\"TITLE\").text)\n",
        "                stage.append(regact.find(\"STAGE\").text)\n",
        "                ES.append(regact.find(\"ECONOMICALLY_SIGNIFICANT\").text)\n",
        "                date_received.append(regact.find(\"DATE_RECEIVED\").text)\n",
        "                legal_deadline.append(regact.find(\"LEGAL_DEADLINE\").text)\n",
        "                date_completed.append(regact.find(\"DATE_COMPLETED\").text)\n",
        "                if regact.find(\"DECISION\") is not None:\n",
        "                  decision.append(regact.find(\"DECISION\").text)\n",
        "                else: decision.append(\"NA\") #\n",
        "                if regact.find(\"DATE_PUBLISHED\")!=None:\n",
        "                    date_published.append(regact.find(\"DATE_PUBLISHED\").text)\n",
        "                else: date_published.append(\"NA\")\n",
        "                if regact.find(\"HEALTH_CARE_ACT\")!=None:\n",
        "                    health_care_act.append(regact.find(\"HEALTH_CARE_ACT\").text) # afford health act after 2009\n",
        "                else: health_care_act.append(\"NA\")\n",
        "                if regact.find(\"DODD_FRANK_ACT\")!=None:\n",
        "                    Dodd_Frank_Act.append(regact.find(\"DODD_FRANK_ACT\").text) # after 2010\n",
        "                else: Dodd_Frank_Act.append(\"NA\")\n",
        "                if regact.find(\"INTERNATIONAL_IMPACTS\")!=None:\n",
        "                    international_impacts.append(regact.find(\"INTERNATIONAL_IMPACTS\").text)\n",
        "                else: international_impacts.append(\"NA\")\n",
        "                if regact.find(\"UNFUNDED_MANDATES\")!=None:\n",
        "                    unfunded_mandates.append(regact.find(\"UNFUNDED_MANDATES\").text)\n",
        "                else: unfunded_mandates.append(\"NA\")\n",
        "                if regact.find(\"MAJOR\")!=None:\n",
        "                    major.append(regact.find(\"MAJOR\").text)\n",
        "                else: major.append(\"NA\")\n",
        "                if regact.find(\"HOMELAND_SECURITY\")!=None:\n",
        "                    homeland_security.append(regact.find(\"HOMELAND_SECURITY\").text)\n",
        "                else: homeland_security.append(\"NA\")\n",
        "                if regact.find(\"REGULATORY_FLEXIBILITY_ANALYSIS\")!=None:\n",
        "                    regulatory_flexibility_analysis.append(regact.find(\"REGULATORY_FLEXIBILITY_ANALYSIS\").text)\n",
        "                else: regulatory_flexibility_analysis.append(\"NA\")\n",
        "\n",
        "    # Convert lists to a dataframe\n",
        "    df_xml=pd.DataFrame(list(zip(agency_code, rin, title, stage, ES, date_received,\\\n",
        "                                 legal_deadline, date_completed, decision, date_published,\\\n",
        "                                 health_care_act, Dodd_Frank_Act, international_impacts,\\\n",
        "                                 unfunded_mandates, major, homeland_security, regulatory_flexibility_analysis)),\\\n",
        "                         columns=[\"agency_code\",\"rin\",\"title\",\"stage\",\"ES\",\\\n",
        "                                 \"date_received\",\"legal_deadline\",\"date_completed\", \"decision\",\\\n",
        "                                 \"date_published\", \"health_care_act\",\"Dodd_Frank_Act\",\"international_impacts\",\\\n",
        "                                 \"unfunded_mandates\",\"major\",\"homeland_security\",\"regulatory_flexibility_analysis\"])\n",
        "\n",
        "    df_fin = pd.merge(df_xml,agy_info,on=\"agency_code\",how='left')\n",
        "\n",
        "    reorder_column = df_fin.pop('agency_name')\n",
        "    df_fin.insert(1, 'agency_name', reorder_column)\n",
        "\n",
        "    return df_fin\n"
      ],
      "metadata": {
        "id": "rkp0oHeZ5N44",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Function to download a XML file\n",
        "def download_xml(year):\n",
        "    file_path = f'/content/EO_RULE_COMPLETED_{year}.xml'\n",
        "\n",
        "    try:\n",
        "        if not os.path.exists(file_path):\n",
        "            if year == current_year:\n",
        "                file_url = f'https://www.reginfo.gov/public/do/XMLViewFileAction?f=EO_RULE_COMPLETED_YTD.xml'\n",
        "            else:\n",
        "                file_url = f'https://www.reginfo.gov/public/do/XMLViewFileAction?f=EO_RULE_COMPLETED_{year}.xml'\n",
        "\n",
        "            r = requests.get(file_url, allow_redirects=True)\n",
        "\n",
        "            if 'DATE_RECEIVED' in r.content.decode(\"utf-8\"):    #check if the correct XML has been downloaded\n",
        "                open(file_path, 'wb').write(r.content)\n",
        "                print(f'EO_RULE_COMPLETED_{year}.xml has been downloaded.')\n",
        "            else:\n",
        "                print(f'ERROR: EO_RULE_COMPLETED_{year}.xml cannot be downloaded.')\n",
        "                file_path=None\n",
        "\n",
        "        else:\n",
        "            print( f'EO_RULE_COMPLETED_{year}.xml already exists in the directory.')\n",
        "\n",
        "    except:\n",
        "        print(f'ERROR: EO_RULE_COMPLETED_{year}.xml cannot be downloaded.')\n",
        "        file_path=None\n",
        "        pass\n",
        "\n",
        "    return file_path"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HoPQpzeqgU5w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "#%% Main function to download XML and convert to CSV within a given time interval (based on user input)\n",
        "\n",
        "#for multiple years\n",
        "def collect_oira_data_multi(start_year,end_year):\n",
        "      result_xml = []\n",
        "      result_csv = []\n",
        "\n",
        "      # Download XML files\n",
        "      if (start_year != end_year):\n",
        "          for year in range(start_year, (end_year+1)):\n",
        "              file_path=download_xml(year)\n",
        "              if file_path!=None:\n",
        "                  result_xml.append(file_path)\n",
        "\n",
        "      # Convert all downloaded XML files into a single CSV file\n",
        "      if len(result_xml)>0:\n",
        "          for j in result_xml:\n",
        "              new_csv = oira_tranformation(j)\n",
        "              result_csv.append(new_csv)\n",
        "\n",
        "          df_res = pd.concat(result_csv, ignore_index=True)\n",
        "          df_res.to_csv(f'/content/EO_RULE_COMPLETED_{start_year}-{end_year}.csv', index=False)\n",
        "          print(f'A CSV file for OIRA review data {start_year}-{end_year} has been created!'\n",
        "                f'\\nClick the Files icon on the left to view and download the CSV file.')\n",
        "\n",
        "      else:\n",
        "          print(f'ERROR: Your requested data cannot be downloaded.'\n",
        "                f'\\nPlease retry in a moment. If the issue persists, contact the author for further assistance.')\n",
        "\n",
        "      return\n",
        "\n",
        "#for a single year\n",
        "def collect_oira_data_single(year):\n",
        "      result_xml = []\n",
        "      result_csv = []\n",
        "\n",
        "      # Download XML files\n",
        "      file_path=download_xml(year)\n",
        "      if file_path!=None:\n",
        "          result_xml.append(file_path)\n",
        "\n",
        "      # Convert all downloaded XML files into a single CSV file\n",
        "      if len(result_xml)>0:\n",
        "          for j in result_xml:\n",
        "              new_csv = oira_tranformation(j)\n",
        "              result_csv.append(new_csv)\n",
        "\n",
        "          df_res = pd.concat(result_csv, ignore_index=True)\n",
        "          df_res.to_csv(f'/content/EO_RULE_COMPLETED_{year}.csv', index=False)\n",
        "          print(f'A CSV file for OIRA review data {year} has been created!'\n",
        "                f'\\nClick the Files icon on the left to view and download the CSV file.')\n",
        "\n",
        "      else:\n",
        "          print(f'ERROR: Your requested data cannot be downloaded.'\n",
        "                f'\\nPlease retry in a moment. If the issue persists, contact the author for further assistance.')\n",
        "\n",
        "      return"
      ],
      "metadata": {
        "id": "18EIJNdJWhfM",
        "cellView": "form"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Functions to check and get user input year\n",
        "current_time = datetime.now()  # using now() to get current time\n",
        "current_year = current_time.year\n",
        "\n",
        "def input_year_option(year_option):\n",
        "    search_option = ['s','m']\n",
        "    while True:\n",
        "        year_option = input(f'Are you requesting data for a single year or multiple years? Please enter \"s\" (single) or \"m\" (multiple): ').lower()\n",
        "        if year_option in search_option:\n",
        "            return year_option\n",
        "            break\n",
        "        else:\n",
        "            print(f'ERROR: Your input \"{year_option}\" is not valid.')\n",
        "\n",
        "\n",
        "def input_year_check(year_type='year'):\n",
        "    year_range = range(1981, current_year+1)\n",
        "    while True:\n",
        "        year=int(input(f'Please enter the {year_type} of the data you are requesting: '))\n",
        "        if year in year_range:\n",
        "            return year\n",
        "            break\n",
        "        else:\n",
        "            print(f'ERROR: Your input year {year} is not in the valid time range.')\n"
      ],
      "metadata": {
        "id": "v33Vk0_-52Oq",
        "cellView": "form"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# User input\n",
        "print(f'The OIRA review data are available from 1981 through {current_year}.\\n')\n",
        "print(f'To request data, please select the single- or multi-year option and then enter the year range between 1981 and {current_year}.')\n",
        "print('(To interrupt execution, click the stop icon in the top left corner of this cell.)\\n')\n",
        "\n",
        "option = input_year_option('option')\n",
        "\n",
        "if option == 's':\n",
        "  single_year = input_year_check('single year')\n",
        "  print('\\nFiles are being downloaded (it may take a few munites)...\\n')\n",
        "  collect_oira_data_single(single_year)\n",
        "else:\n",
        "  start_year = input_year_check('start year')\n",
        "  end_year = input_year_check('end year')\n",
        "  print('\\nFiles are being downloaded (it may take a few munites)...\\n')\n",
        "  collect_oira_data_multi(start_year, end_year)\n",
        "\n",
        "print('\\nEnd of execution!')\n",
        "print('To start a new request, please re-run the code.')"
      ],
      "metadata": {
        "id": "T7xJNl-ejNZs",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}