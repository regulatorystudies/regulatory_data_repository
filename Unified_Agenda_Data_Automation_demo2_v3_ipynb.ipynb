{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhoudanxie/regulatory_data_repository/blob/main/Unified_Agenda_Data_Automation_demo2_v3_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Library"
      ],
      "metadata": {
        "id": "rrRODnnZqEM5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPEL-UtgKMxZ"
      },
      "outputs": [],
      "source": [
        "# library\n",
        "import warnings\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import xml.etree.cElementTree as et\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_columns', 10)\n",
        "from lxml import etree\n",
        "import requests\n",
        "import ipywidgets as widgets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Automation"
      ],
      "metadata": {
        "id": "j7ugyNJZqOJ5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HCCyoIHjpWH"
      },
      "outputs": [],
      "source": [
        "def replace_noun(text):\n",
        "    if text==None:\n",
        "        text='N/A'\n",
        "    else:\n",
        "        text=text\n",
        "    return text\n",
        "\n",
        "# %% Revised function\n",
        "def xml_to_csv(file):\n",
        "\n",
        "    # Create empty lists to store values\n",
        "    agenda_date,RIN,agency_code,agency_name,department_code,department_name,rule_title,abstract,\\\n",
        "        priority,RIN_status,rule_stage,major,CFR,legal_authority,legal_deadline_list,action_list= ([] for i in range(16))\n",
        "\n",
        "    # Parse XML\n",
        "    parser = etree.XMLParser(encoding=\"UTF-8\", recover=True)\n",
        "    parsed_xml = etree.parse(file, parser)  # prevent form issue\n",
        "    root = parsed_xml.getroot()\n",
        "\n",
        "    for child in root:\n",
        "        agenda_date.append(child.find('PUBLICATION')[0].text)\n",
        "        RIN.append(child.find('RIN').text)\n",
        "        agency_code.append(child.find('AGENCY')[0].text)\n",
        "\n",
        "        if child.find('AGENCY').find('NAME') != None:\n",
        "            agency_name.append(child.find('AGENCY').find('NAME').text)\n",
        "        else:\n",
        "            agency_name.append('')\n",
        "\n",
        "        if child.find('PARENT_AGENCY') != None:\n",
        "            department_code.append(child.find('PARENT_AGENCY')[0].text)\n",
        "            department_name.append(child.find('PARENT_AGENCY')[1].text)\n",
        "        else:\n",
        "            department_code.append('')\n",
        "            department_name.append('')\n",
        "\n",
        "        rule_title.append(child.find('RULE_TITLE').text)\n",
        "        abstract.append(child.find('ABSTRACT').text)\n",
        "\n",
        "        if child.find('PRIORITY_CATEGORY') != None:\n",
        "            priority.append(child.find('PRIORITY_CATEGORY').text)\n",
        "        else:\n",
        "            priority.append('')\n",
        "        if child.find('RIN_STATUS') != None:\n",
        "            RIN_status.append(child.find('RIN_STATUS').text)\n",
        "        else:\n",
        "            RIN_status.append('')\n",
        "        if child.find('RULE_STAGE') != None:\n",
        "            rule_stage.append(child.find('RULE_STAGE').text)\n",
        "        else:\n",
        "            rule_stage.append('')\n",
        "        if child.find('MAJOR') != None:\n",
        "            major.append(child.find('MAJOR').text)\n",
        "        else:\n",
        "            major.append('')\n",
        "\n",
        "        if child.find('CFR_LIST') != None:\n",
        "            index = 0\n",
        "            cfr_text = ''\n",
        "            while (index < len(list(child.find('CFR_LIST')))):\n",
        "                add = child.find('CFR_LIST')[index].text\n",
        "                if cfr_text == '':\n",
        "                    cfr_text = add\n",
        "                else:\n",
        "                    cfr_text = cfr_text + \"; \" + str(add)\n",
        "                index = index + 1\n",
        "            CFR.append(cfr_text)\n",
        "        else:\n",
        "            CFR.append('')\n",
        "\n",
        "        if child.find('LEGAL_AUTHORITY_LIST') != None:\n",
        "            index = 0\n",
        "            lauth_text = ''\n",
        "            while (index < len(list(child.find('LEGAL_AUTHORITY_LIST')))):\n",
        "                add = child.find('LEGAL_AUTHORITY_LIST')[index].text\n",
        "                if lauth_text == '':\n",
        "                    lauth_text = add\n",
        "                else:\n",
        "                    lauth_text = lauth_text + \"; \" + str(add)\n",
        "                index = index + 1\n",
        "            legal_authority.append(lauth_text)\n",
        "        else:\n",
        "            legal_authority.append('')\n",
        "\n",
        "        if child.find('LEGAL_DLINE_LIST') is not None:\n",
        "            legal_deadlines = []\n",
        "            if child.find('LEGAL_DLINE_LIST').find('LEGAL_DLINE_INFO') != None:\n",
        "                for element in child.find('LEGAL_DLINE_LIST').findall('LEGAL_DLINE_INFO'):\n",
        "                    lddl_text = replace_noun(element.find('DLINE_TYPE').text) + '; ' + \\\n",
        "                                replace_noun(element.find('DLINE_ACTION_STAGE').text) + '; ' + \\\n",
        "                                replace_noun(element.find('DLINE_DATE').text) + '; ' + \\\n",
        "                                replace_noun(element.find('DLINE_DESC').text)\n",
        "                    legal_deadlines.append(lddl_text)\n",
        "            legal_deadline_list.append(legal_deadlines)\n",
        "        else:\n",
        "            legal_deadline_list.append([])\n",
        "\n",
        "        if child.find('TIMETABLE_LIST') != None:\n",
        "            actions=[]\n",
        "            for element in child.find('TIMETABLE_LIST').findall('TIMETABLE'):\n",
        "                if element.find('FR_CITATION') != None:\n",
        "                    action_text = element.find('TTBL_ACTION').text + '; ' + \\\n",
        "                                    element.find('TTBL_DATE').text + '; ' + \\\n",
        "                                    element.find('FR_CITATION').text\n",
        "                else:\n",
        "                    if element.find('TTBL_DATE') != None:\n",
        "                        action_text = element.find('TTBL_ACTION').text + '; ' + \\\n",
        "                                        element.find('TTBL_DATE').text\n",
        "                    else:\n",
        "                        action_text = element.find('TTBL_ACTION').text\n",
        "                actions.append(action_text)\n",
        "            action_list.append(actions)\n",
        "        else:\n",
        "            action_list.append([])\n",
        "\n",
        "    # Convert lists to a dataframe\n",
        "    df_xml=pd.DataFrame(list(zip(agenda_date,RIN,agency_code,agency_name,department_code,department_name,\\\n",
        "                        rule_title,abstract,priority,RIN_status,rule_stage,major,CFR,legal_authority,\\\n",
        "                        legal_deadline_list,action_list)),\\\n",
        "              columns=['agenda_date','RIN','agency_code','agency_name','department_code','department_name',\\\n",
        "                        'rule_title','abstract','priority','RIN_status','rule_stage','major','CFR','legal_authority',\\\n",
        "                        'legal_deadline_list','action_list'])\n",
        "\n",
        "    # Split legal deadline and action columns\n",
        "    lddl_max = max([len(l) for l in df_xml['legal_deadline_list']])\n",
        "    lddl_cols = []\n",
        "    for i in range(1, lddl_max + 1):\n",
        "        lddl_cols.append('legal_deadline' + str(i))\n",
        "    df_xml[lddl_cols] = pd.DataFrame(df_xml['legal_deadline_list'].tolist(), index=df_xml.index)\n",
        "\n",
        "    action_max = max([len(l) for l in df_xml['action_list']])\n",
        "    action_cols = []\n",
        "    for i in range(1, action_max + 1):\n",
        "        action_cols.append('action' + str(i))\n",
        "    df_xml[action_cols] = pd.DataFrame(df_xml['action_list'].tolist(), index=df_xml.index)\n",
        "\n",
        "    df_xml.drop(['legal_deadline_list','action_list'],axis=1,inplace=True)\n",
        "\n",
        "    return df_xml\n",
        "\n",
        "\n",
        "\n",
        "#%% Define a function to download XML and convert to CSV within a given time interval (based on user input)\n",
        "def time_interval_transform(start_year,start_season,end_year,end_season):\n",
        "\n",
        "\n",
        "\n",
        "    files_failed=[]\n",
        "    result_xml = []\n",
        "    result_csv = []\n",
        "    single_xml = []\n",
        "    single_csv = []\n",
        "    sea_option = ['04','10']\n",
        "\n",
        "    # season str to int conversion\n",
        "    def season_transform(s):\n",
        "      season = ['04', '10']\n",
        "      if s == 'Fall':\n",
        "            return season[1]   #this is an str\n",
        "\n",
        "      elif s == 'Spring':\n",
        "          return season[0]\n",
        "         #this is a str\n",
        "      else:\n",
        "        return f'Wrong season value, please only enter \"Spring\" and \"Fall\" for season option'\n",
        "\n",
        "    season1 = season_transform(start_season)\n",
        "    season2 = season_transform(end_season)\n",
        "\n",
        "    ### single download\n",
        "    def auto_single_download(year,season):\n",
        "\n",
        "      season = season_transform(season)\n",
        "      file_path = '/content/' + f'REGINFO_RIN_DATA_{year}{season}.xml'\n",
        "      files_failed=[]\n",
        "\n",
        "      try:\n",
        "        if not os.path.exists(file_path):\n",
        "          file_url = f'https://www.reginfo.gov/public/do/XMLViewFileAction?f=REGINFO_RIN_DATA_{year}{season}.xml'\n",
        "          r = requests.get(file_url, allow_redirects=True)\n",
        "          open(file_path, 'wb').write(r.content)\n",
        "          df = xml_to_csv(file_path) # transfer xml file to dataframe\n",
        "          return df\n",
        "          print(f'{year}{season} has been downloaded')\n",
        "\n",
        "        else:\n",
        "          print( f'File already exists in the directory')\n",
        "          df = xml_to_csv(file_path) # transfer existed xml file to dataframe\n",
        "          return df\n",
        "\n",
        "      except:\n",
        "        files_failed.append(f'{year}{season}')\n",
        "        print(f'{year}{season} cannot be downloaded')\n",
        "\n",
        "    #return df\n",
        "\n",
        "\n",
        "\n",
        "    #condition 1: Extract single/both season file from same year\n",
        "    if (end_year == start_year):\n",
        "\n",
        "      if start_year == 2012:\n",
        "\n",
        "            try:\n",
        "              file_path1 = '/content/' + f'REGINFO_RIN_DATA_2012.xml'\n",
        "              if not os.path.exists(file_path1):\n",
        "                file_url = f'https://www.reginfo.gov/public/do/XMLViewFileAction?f=REGINFO_RIN_DATA_2012.xml'\n",
        "                r = requests.get(file_url, allow_redirects=True)\n",
        "                open(file_path1, 'wb').write(r.content)\n",
        "\n",
        "                df = xml_to_csv(file_path1)\n",
        "                df.to_csv(f'/content/REGINFO_RIN_DATA_2012.csv')\n",
        "\n",
        "                print(f'2012 has been downloaded')\n",
        "\n",
        "              else:\n",
        "                df = xml_to_csv(file_path1)\n",
        "                df.to_csv(f'/content/REGINFO_RIN_DATA_2012.csv')\n",
        "                print( f'2012 already exists in the directory')\n",
        "\n",
        "            except:\n",
        "                files_failed.append(f'2012')\n",
        "                print(f'2012 cannot be downloaded')\n",
        "                pass\n",
        "\n",
        "\n",
        "\n",
        "      else:\n",
        "\n",
        "        if (start_season==end_season):\n",
        "\n",
        "          single_file = auto_single_download(start_year, start_season)\n",
        "          single_file.to_csv(f'/content/REGINFO_RIN_DATA_{start_year}{start_season}.csv')\n",
        "          print(f'{start_year} {start_season} has been downloaded')\n",
        "\n",
        "        else:\n",
        "\n",
        "          sea_1 = auto_single_download(start_year, start_season)\n",
        "          sea_2 = auto_single_download(end_year, end_season)\n",
        "\n",
        "          df_single_res = pd.concat([sea_1,sea_2], ignore_index=True)\n",
        "\n",
        "          df_single_res.to_csv(f'/content/REGINFO_RIN_DATA_{start_year}{start_season}&{end_season}.csv', index=False)\n",
        "          print(f'A CSV file for Unified Agenda {start_year}{start_season}&{end_season}.csv has been created!')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # condition 2: for start year\n",
        "    # 2012 check\n",
        "    elif (start_year != end_year) : # to indicate specific condition\n",
        "      if start_year == 2012:\n",
        "\n",
        "            try:\n",
        "              file_path1 = '/content/' + f'REGINFO_RIN_DATA_2012.xml'\n",
        "              if not os.path.exists(file_path1):\n",
        "                file_url = f'https://www.reginfo.gov/public/do/XMLViewFileAction?f=REGINFO_RIN_DATA_2012.xml'\n",
        "                r = requests.get(file_url, allow_redirects=True)\n",
        "                open(file_path1, 'wb').write(r.content)\n",
        "                result_xml.append(file_path1)\n",
        "\n",
        "                print(f'2012 has been downloaded')\n",
        "\n",
        "              else:\n",
        "                print( f'2012 already exists in the directory')\n",
        "                result_xml.append(file_path1) # appended file if already existed\n",
        "\n",
        "            except:\n",
        "                files_failed.append(f'2012')\n",
        "                print(f'2012 cannot be downloaded')\n",
        "                pass\n",
        "\n",
        "          # years other than 2012\n",
        "      else:\n",
        "\n",
        "        if season1 == '10':\n",
        "\n",
        "\n",
        "              file_path = '/content/' + f'REGINFO_RIN_DATA_{start_year}{season1}.xml'\n",
        "\n",
        "              try:\n",
        "                if not os.path.exists(file_path):\n",
        "                  file_url = f'https://www.reginfo.gov/public/do/XMLViewFileAction?f=REGINFO_RIN_DATA_{start_year}{season1}.xml'\n",
        "                  r = requests.get(file_url, allow_redirects=True)\n",
        "                  open(file_path, 'wb').write(r.content)\n",
        "                  result_xml.append(file_path)\n",
        "\n",
        "                  print(f'{start_year}{season1} has been downloaded')\n",
        "\n",
        "                else:\n",
        "                  print( f'{start_year}{season1} already exists in the directory')\n",
        "                  result_xml.append(file_path) # appended exist file\n",
        "\n",
        "              except:\n",
        "                  files_failed.append(f'{start_year}{season1}')\n",
        "                  print(f'{start_year}{season1} cannot be downloaded')\n",
        "                  pass\n",
        "\n",
        "        else:\n",
        "\n",
        "          for i in sea_option:\n",
        "            file_path = '/content/' + f'REGINFO_RIN_DATA_{start_year}{i}.xml'\n",
        "\n",
        "\n",
        "            try:\n",
        "              if not os.path.exists(file_path):\n",
        "                file_url = f'https://www.reginfo.gov/public/do/XMLViewFileAction?f=REGINFO_RIN_DATA_{start_year}{i}.xml'\n",
        "                r = requests.get(file_url, allow_redirects=True)\n",
        "                open(file_path, 'wb').write(r.content)\n",
        "                result_xml.append(file_path)\n",
        "\n",
        "                print(f'{start_year}{i} has been downloaded')\n",
        "\n",
        "              else:\n",
        "                print( f'{start_year}{i} already exists in the directory')\n",
        "                result_xml.append(file_path) # appended exist file\n",
        "\n",
        "            except:\n",
        "                files_failed.append(f'{start_year}{i}')\n",
        "                print(f'{start_year}{i} cannot be downloaded')\n",
        "                pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Condition 3: For the end year\n",
        "\n",
        "    # 2012 check\n",
        "      if end_year == 2012:\n",
        "\n",
        "            try:\n",
        "              file_path1 = '/content/' + f'REGINFO_RIN_DATA_2012.xml'\n",
        "              if not os.path.exists(file_path1):\n",
        "                file_url = f'https://www.reginfo.gov/public/do/XMLViewFileAction?f=REGINFO_RIN_DATA_2012.xml'\n",
        "                r = requests.get(file_url, allow_redirects=True)\n",
        "                open(file_path1, 'wb').write(r.content)\n",
        "                result_xml.append(file_path1)\n",
        "\n",
        "                print(f'2012 has been downloaded')\n",
        "\n",
        "              else:\n",
        "                print( f'2012 already exists in the directory')\n",
        "                result_xml.append(file_path) # appended exist file\n",
        "\n",
        "            except:\n",
        "                files_failed.append(f'2012')\n",
        "                print(f'2012 cannot be downloaded')\n",
        "                pass\n",
        "\n",
        "      # years other than 2012\n",
        "      else:\n",
        "\n",
        "        if season2 == '04':\n",
        "\n",
        "              file_path = '/content/' + f'REGINFO_RIN_DATA_{end_year}{season2}.xml'\n",
        "\n",
        "              try:\n",
        "                if not os.path.exists(file_path):\n",
        "                  file_url = f'https://www.reginfo.gov/public/do/XMLViewFileAction?f=REGINFO_RIN_DATA_{end_year}{season2}.xml'\n",
        "                  r = requests.get(file_url, allow_redirects=True)\n",
        "                  open(file_path, 'wb').write(r.content)\n",
        "                  result_xml.append(file_path)\n",
        "\n",
        "                  print(f'{end_year}{season2} has been downloaded')\n",
        "\n",
        "                else:\n",
        "                  print( f'{end_year}{season2} already exists in the directory')\n",
        "                  result_xml.append(file_path) # appended exist file\n",
        "\n",
        "              except:\n",
        "                  files_failed.append(f'{end_year}{season2}')\n",
        "                  print(f'{end_year}{season2} cannot be downloaded')\n",
        "                  pass\n",
        "\n",
        "        else:\n",
        "\n",
        "          for i in sea_option:\n",
        "            file_path = '/content/' + f'REGINFO_RIN_DATA_{end_year}{i}.xml'\n",
        "\n",
        "\n",
        "            try:\n",
        "              if not os.path.exists(file_path):\n",
        "                file_url = f'https://www.reginfo.gov/public/do/XMLViewFileAction?f=REGINFO_RIN_DATA_{end_year}{i}.xml'\n",
        "                r = requests.get(file_url, allow_redirects=True)\n",
        "                open(file_path, 'wb').write(r.content)\n",
        "                result_xml.append(file_path)\n",
        "\n",
        "                print(f'{end_year}{i} has been downloaded')\n",
        "\n",
        "              else:\n",
        "                print( f'{end_year}{i} already exists in the directory')\n",
        "                result_xml.append(file_path) # appended exist file\n",
        "\n",
        "            except:\n",
        "                files_failed.append(f'{end_year}{i}')\n",
        "                print(f'{end_year}{i} cannot be downloaded')\n",
        "                pass\n",
        "\n",
        "\n",
        "\n",
        "    # Condition 4: For all the years between the start and end years\n",
        "\n",
        "\n",
        "\n",
        "      for year in range((start_year+1), end_year):\n",
        "\n",
        "          if (end_year - start_year == 1): # skip this for loop if this condition is satisfied\n",
        "            break\n",
        "\n",
        "          # 2012 check\n",
        "          if year == 2012:\n",
        "\n",
        "            try:\n",
        "              file_path1 = '/content/' + f'REGINFO_RIN_DATA_2012.xml'\n",
        "              if not os.path.exists(file_path1):\n",
        "                file_url = f'https://www.reginfo.gov/public/do/XMLViewFileAction?f=REGINFO_RIN_DATA_2012.xml'\n",
        "                r = requests.get(file_url, allow_redirects=True)\n",
        "                open(file_path1, 'wb').write(r.content)\n",
        "                result_xml.append(file_path1)\n",
        "\n",
        "                print(f'2012 has been downloaded')\n",
        "\n",
        "              else:\n",
        "                print( f'2012 already exists in the directory')\n",
        "                result_xml.append(file_path) # appended exist file\n",
        "\n",
        "            except:\n",
        "                files_failed.append(f'2012')\n",
        "                print(f'2012 cannot be downloaded')\n",
        "                pass\n",
        "\n",
        "          # years other than 2012\n",
        "          else:\n",
        "            for i in sea_option:\n",
        "              file_path = '/content/' + f'REGINFO_RIN_DATA_{year}{i}.xml'\n",
        "              try:\n",
        "                if not os.path.exists(file_path):\n",
        "                  file_url = f'https://www.reginfo.gov/public/do/XMLViewFileAction?f=REGINFO_RIN_DATA_{year}{i}.xml'\n",
        "                  r = requests.get(file_url, allow_redirects=True)\n",
        "                  open(file_path, 'wb').write(r.content)\n",
        "                  result_xml.append(file_path)\n",
        "                  print(f'{year}{i} has been downloaded')\n",
        "                else:\n",
        "                  print( f'{year}{i} already exists in the directory')\n",
        "                  result_xml.append(file_path) # appended exist file\n",
        "\n",
        "              except:\n",
        "                files_failed.append(f'{year}{i}')\n",
        "                print('END!','Years failed:',files_failed)\n",
        "                pass\n",
        "\n",
        "    # Convert all downloaded XML files into a single CSV file\n",
        "\n",
        "      for j in result_xml:\n",
        "       new_csv = xml_to_csv(j)\n",
        "       result_csv.append(new_csv)\n",
        "\n",
        "      df_res = pd.concat(result_csv, ignore_index=True)\n",
        "      df_res.to_csv(f'/content/REGINFO_RIN_DATA_{start_year}-{end_year}.csv', index=False)\n",
        "\n",
        "      print(f'A CSV file for Unified Agenda {start_year} {start_season} - {end_year} {end_season} has been created!')\n",
        "\n",
        "    return\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# update to most recent time info\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "# Make a request\n",
        "page = requests.get(\n",
        "    \"https://www.reginfo.gov/public/do/eAgendaXmlReport\")\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "# Extract newest file time information\n",
        "newest_file_info = soup.select('li')[0].text[1:-6]\n",
        "\n",
        "#extract newest year and season\n",
        "current_year_season = re.split(\"\\s\", newest_file_info, 1) #list\n",
        "current_year = int(current_year_season[1]) # int\n",
        "current_season = current_year_season[0] # str\n",
        "print(current_year_season,\n",
        "current_year_season[0], # current season\n",
        "current_year_season[1])  # current year"
      ],
      "metadata": {
        "id": "TPP_-kKPQSwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User Input"
      ],
      "metadata": {
        "id": "lygPzYVbquwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f'Please enter the year and season range from 1995 Fall to latest {current_year} {current_season}')\n",
        "start_year = int(input('Please enter the start year of your search: '))\n",
        "start_season = input('Please enter the season of start year (\"Spring\" or \"Fall\"): ')\n",
        "end_year = int(input('Please enter the end year of your search: '))\n",
        "end_season = input('Please enter the season of end year (\"Spring\" or \"Fall\"): ')\n",
        "\n",
        "\n",
        "\n",
        "range_1 = range(1995,current_year+1)\n",
        "\n",
        "if (start_year not in range_1) or (end_year not in range_1) :\n",
        "  print(f'{start_year} and {end_year} is not in time range. \\nPlease re-enter the year and season range between 1995 Fall and {current_year} {current_season}')\n",
        "\n",
        "else:\n",
        "\n",
        "  if start_year == 1995 and start_season != 'Fall':\n",
        "    print('The file of year 1995 only have season Fall, please only enter Fall for year 1995 file')\n",
        "  elif end_year == current_year:\n",
        "     if end_season == current_season == 'Fall':\n",
        "      time_interval_transform(start_year,start_season,end_year,end_season)\n",
        "     elif current_season == 'Spring':\n",
        "      if end_season != current_season:\n",
        "        print(f'The most latest file time is {current_year} Spring on the websit. \\nIf extracting latest file, please only use Spring for latest file season  ')\n",
        "      else:\n",
        "        time_interval_transform(start_year,start_season,end_year,end_season)\n",
        "     else:\n",
        "      print('Please only enter Spring and Fall for season option')\n",
        "  else:\n",
        "    time_interval_transform(start_year,start_season,end_year,end_season)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1jBKAeY5jg4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To-Do List, 7/10/2023:\n",
        "- when inputing 2012 Spring and 2012 Fall, it does not show the message \"A CSV file for ... has been created.\"\n",
        "- use lower() for start_season and end_season to make it case insensitive\n",
        "- Revise message output to be error-free and user-friendly\n",
        "- Refine the code to be more efficient\n",
        "- Put all the code into one single cell (so the user only needs to hit Run once)\n",
        "- Explore ways other than Google Colab to allow users to run code\n",
        "- Develop similar code for OIRA review data"
      ],
      "metadata": {
        "id": "IX6Y3NJMYpGr"
      }
    }
  ]
}